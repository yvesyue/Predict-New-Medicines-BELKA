{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce6a0e",
   "metadata": {
    "papermill": {
     "duration": 0.003904,
     "end_time": "2024-05-01T18:46:30.989256",
     "exception": false,
     "start_time": "2024-05-01T18:46:30.985352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we will train a deep learning model using all the data available !\n",
    "* preprocessing : I encoded the smiles of all the train & test set and saved it [here](https://www.kaggle.com/datasets/ahmedelfazouan/belka-enc-dataset) , this may take up to 1 hour on TPU.\n",
    "* Training & Inference : I used a simple 1dcnn model trained on 20 epochs.\n",
    "\n",
    "How to improve :\n",
    "* Try a different architecture : I'm able to get an LB score of 0.604 with minor changes on this architecture.\n",
    "* Try another model like Transformer, or LSTM.\n",
    "* Train for more epochs.\n",
    "* Add more features like a one hot encoding of bb2 or bb3.\n",
    "* And of course ensembling with GBDT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8733e7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-01T18:46:30.996383Z",
     "iopub.status.busy": "2024-05-01T18:46:30.996139Z",
     "iopub.status.idle": "2024-05-01T18:46:36.887373Z",
     "shell.execute_reply": "2024-05-01T18:46:36.886544Z"
    },
    "papermill": {
     "duration": 5.897434,
     "end_time": "2024-05-01T18:46:36.889788",
     "exception": false,
     "start_time": "2024-05-01T18:46:30.992354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a5ac7a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-01T18:46:36.897495Z",
     "iopub.status.busy": "2024-05-01T18:46:36.897240Z",
     "iopub.status.idle": "2024-05-01T18:46:39.716516Z",
     "shell.execute_reply": "2024-05-01T18:46:39.715705Z"
    },
    "papermill": {
     "duration": 2.825731,
     "end_time": "2024-05-01T18:46:39.718772",
     "exception": false,
     "start_time": "2024-05-01T18:46:36.893041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d25b849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:46:39.726972Z",
     "iopub.status.busy": "2024-05-01T18:46:39.726410Z",
     "iopub.status.idle": "2024-05-01T18:46:39.730854Z",
     "shell.execute_reply": "2024-05-01T18:46:39.730132Z"
    },
    "papermill": {
     "duration": 0.010447,
     "end_time": "2024-05-01T18:46:39.732594",
     "exception": false,
     "start_time": "2024-05-01T18:46:39.722147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    PREPROCESS = False\n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-3\n",
    "    WD = 0.05\n",
    "\n",
    "    NBR_FOLDS = 15\n",
    "    SELECTED_FOLDS = [0]\n",
    "\n",
    "    SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea165bc7",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-01T18:46:39.739819Z",
     "iopub.status.busy": "2024-05-01T18:46:39.739191Z",
     "iopub.status.idle": "2024-05-01T18:47:18.170076Z",
     "shell.execute_reply": "2024-05-01T18:47:18.169272Z"
    },
    "papermill": {
     "duration": 38.436952,
     "end_time": "2024-05-01T18:47:18.172433",
     "exception": false,
     "start_time": "2024-05-01T18:46:39.735481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D0501 18:47:11.011512963      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D0501 18:47:11.011555226      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D0501 18:47:11.011559478      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D0501 18:47:11.011562524      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\n",
      "D0501 18:47:11.011565349      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D0501 18:47:11.011568108      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D0501 18:47:11.011571426      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\n",
      "D0501 18:47:11.011574187      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D0501 18:47:11.011576921      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D0501 18:47:11.011579666      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D0501 18:47:11.011582327      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D0501 18:47:11.011584981      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D0501 18:47:11.011587796      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D0501 18:47:11.011590373      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "I0501 18:47:11.011789784      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 59\n",
      "D0501 18:47:11.011803395      14 ev_posix.cc:144]                      Using polling engine: epoll1\n",
      "D0501 18:47:11.011824399      14 dns_resolver_ares.cc:822]             Using ares dns resolver\n",
      "D0501 18:47:11.012336608      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0501 18:47:11.012345793      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0501 18:47:11.012349768      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0501 18:47:11.012353136      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0501 18:47:11.012356525      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0501 18:47:11.012360000      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\n",
      "D0501 18:47:11.012368621      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0501 18:47:11.012393081      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0501 18:47:11.012436376      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0501 18:47:11.012454180      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0501 18:47:11.012458006      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0501 18:47:11.012461673      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0501 18:47:11.012465283      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D0501 18:47:11.012468829      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0501 18:47:11.012472429      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0501 18:47:11.012477640      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\n",
      "I0501 18:47:11.016149511      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0501 18:47:11.048593478      14 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0501 18:47:11.056033774      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-05-01T18:47:11.056016579+00:00\"}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ae49f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:47:18.180979Z",
     "iopub.status.busy": "2024-05-01T18:47:18.180499Z",
     "iopub.status.idle": "2024-05-01T18:47:27.177728Z",
     "shell.execute_reply": "2024-05-01T18:47:27.176646Z"
    },
    "papermill": {
     "duration": 9.005379,
     "end_time": "2024-05-01T18:47:27.181576",
     "exception": false,
     "start_time": "2024-05-01T18:47:18.176197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "Running on TPU\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU\")\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "except tf.errors.NotFoundError:\n",
    "    print(\"Not on TPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327be3e8",
   "metadata": {
    "papermill": {
     "duration": 0.004058,
     "end_time": "2024-05-01T18:47:27.190251",
     "exception": false,
     "start_time": "2024-05-01T18:47:27.186193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f9e651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:47:27.200138Z",
     "iopub.status.busy": "2024-05-01T18:47:27.199869Z",
     "iopub.status.idle": "2024-05-01T18:49:14.945927Z",
     "shell.execute_reply": "2024-05-01T18:49:14.944788Z"
    },
    "papermill": {
     "duration": 107.753795,
     "end_time": "2024-05-01T18:49:14.948371",
     "exception": false,
     "start_time": "2024-05-01T18:47:27.194576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.PREPROCESS:\n",
    "    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n",
    "           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n",
    "           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36}\n",
    "    train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n",
    "    smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n",
    "    def encode_smile(smile):\n",
    "        tmp = [enc[i] for i in smile]\n",
    "        tmp = tmp + [0]*(142-len(tmp))\n",
    "        return np.array(tmp).astype(np.uint8)\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "    train.to_parquet('train_enc.parquet')\n",
    "\n",
    "    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "    smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    test.to_parquet('test_enc.parquet')\n",
    "\n",
    "else:\n",
    "    train = pd.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet')\n",
    "    test = pd.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e734c",
   "metadata": {
    "papermill": {
     "duration": 0.00387,
     "end_time": "2024-05-01T18:49:14.956761",
     "exception": false,
     "start_time": "2024-05-01T18:49:14.952891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1afa3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:49:14.966288Z",
     "iopub.status.busy": "2024-05-01T18:49:14.965832Z",
     "iopub.status.idle": "2024-05-01T18:49:14.975693Z",
     "shell.execute_reply": "2024-05-01T18:49:14.974926Z"
    },
    "papermill": {
     "duration": 0.016638,
     "end_time": "2024-05-01T18:49:14.977193",
     "exception": false,
     "start_time": "2024-05-01T18:49:14.960555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    with strategy.scope():\n",
    "        INP_LEN = 142\n",
    "        NUM_FILTERS = 32\n",
    "        hidden_dim = 128\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=(INP_LEN,), dtype='int32')\n",
    "        x = tf.keras.layers.Embedding(input_dim=36, output_dim=hidden_dim, input_length=INP_LEN, mask_zero = True)(inputs)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*2, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*3, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "        outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n",
    "        loss = 'binary_crossentropy'\n",
    "        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n",
    "        model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        weighted_metrics=weighted_metrics,\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe5632",
   "metadata": {
    "papermill": {
     "duration": 0.004269,
     "end_time": "2024-05-01T18:49:14.985271",
     "exception": false,
     "start_time": "2024-05-01T18:49:14.981002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eaffe47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:49:14.994506Z",
     "iopub.status.busy": "2024-05-01T18:49:14.994263Z",
     "iopub.status.idle": "2024-05-01T20:24:55.851999Z",
     "shell.execute_reply": "2024-05-01T20:24:55.850720Z"
    },
    "papermill": {
     "duration": 5740.865752,
     "end_time": "2024-05-01T20:24:55.854787",
     "exception": false,
     "start_time": "2024-05-01T18:49:14.989035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 18:53:42.754461: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_30/ReadVariableOp.\n",
      "2024-05-01 18:53:42.896005: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_30/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22426/22426 [==============================] - ETA: 0s - loss: 0.0153 - avg_precision: 0.5266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 18:58:21.382090: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n",
      "2024-05-01 18:58:21.487473: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22426/22426 [==============================] - 297s 13ms/step - loss: 0.0153 - avg_precision: 0.5266 - val_loss: 0.0134 - val_avg_precision: 0.5987 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0133 - avg_precision: 0.6038 - val_loss: 0.0129 - val_avg_precision: 0.6222 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0130 - avg_precision: 0.6174 - val_loss: 0.0127 - val_avg_precision: 0.6297 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0128 - avg_precision: 0.6236 - val_loss: 0.0127 - val_avg_precision: 0.6333 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0127 - avg_precision: 0.6275 - val_loss: 0.0125 - val_avg_precision: 0.6380 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0127 - avg_precision: 0.6306 - val_loss: 0.0125 - val_avg_precision: 0.6391 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0126 - avg_precision: 0.6323 - val_loss: 0.0124 - val_avg_precision: 0.6422 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0126 - avg_precision: 0.6340 - val_loss: 0.0125 - val_avg_precision: 0.6418 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "22426/22426 [==============================] - 269s 12ms/step - loss: 0.0125 - avg_precision: 0.6356 - val_loss: 0.0124 - val_avg_precision: 0.6415 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0125 - avg_precision: 0.6365 - val_loss: 0.0123 - val_avg_precision: 0.6435 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0125 - avg_precision: 0.6375 - val_loss: 0.0123 - val_avg_precision: 0.6446 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0125 - avg_precision: 0.6385 - val_loss: 0.0124 - val_avg_precision: 0.6426 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "22426/22426 [==============================] - 269s 12ms/step - loss: 0.0124 - avg_precision: 0.6391 - val_loss: 0.0123 - val_avg_precision: 0.6468 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0124 - avg_precision: 0.6399 - val_loss: 0.0122 - val_avg_precision: 0.6503 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "22426/22426 [==============================] - 272s 12ms/step - loss: 0.0124 - avg_precision: 0.6407 - val_loss: 0.0122 - val_avg_precision: 0.6515 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "22426/22426 [==============================] - 269s 12ms/step - loss: 0.0124 - avg_precision: 0.6412 - val_loss: 0.0122 - val_avg_precision: 0.6490 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0124 - avg_precision: 0.6416 - val_loss: 0.0122 - val_avg_precision: 0.6478 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "22426/22426 [==============================] - 271s 12ms/step - loss: 0.0124 - avg_precision: 0.6422 - val_loss: 0.0123 - val_avg_precision: 0.6506 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "22425/22426 [============================>.] - ETA: 0s - loss: 0.0124 - avg_precision: 0.6428\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0124 - avg_precision: 0.6428 - val_loss: 0.0122 - val_avg_precision: 0.6520 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "22426/22426 [==============================] - 270s 12ms/step - loss: 0.0115 - avg_precision: 0.6799 - val_loss: 0.0112 - val_avg_precision: 0.6893 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 20:24:22.952656: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-05-01 20:24:23.020243: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 12s 11ms/step\n",
      "fold : 0 CV score = 0.6913365165517639\n",
      "205/205 [==============================] - 4s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "FEATURES = [f'enc{i}' for i in range(142)]\n",
    "TARGETS = ['bind1', 'bind2', 'bind3']\n",
    "skf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42)\n",
    "\n",
    "all_preds = []\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(train, train[TARGETS].sum(1))):\n",
    "    \n",
    "    if fold not in CFG.SELECTED_FOLDS:\n",
    "        continue;\n",
    "    \n",
    "    X_train = train.loc[train_idx, FEATURES]\n",
    "    y_train = train.loc[train_idx, TARGETS]\n",
    "    X_val = train.loc[valid_idx, FEATURES]\n",
    "    y_val = train.loc[valid_idx, TARGETS]\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"model-{fold}.h5\",\n",
    "                                                        save_best_only=True, save_weights_only=True,\n",
    "                                                    mode='min')\n",
    "    reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\n",
    "    model = my_model()\n",
    "    history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=CFG.EPOCHS,\n",
    "            callbacks=[checkpoint, reduce_lr_loss, es],\n",
    "            batch_size=CFG.BATCH_SIZE,\n",
    "            verbose=1,\n",
    "        )\n",
    "    model.load_weights(f\"model-{fold}.h5\")\n",
    "    oof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\n",
    "    print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "    \n",
    "    preds = model.predict(test, batch_size = 2*CFG.BATCH_SIZE)\n",
    "    all_preds.append(preds)\n",
    "\n",
    "preds = np.mean(all_preds, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e581e",
   "metadata": {
    "papermill": {
     "duration": 5.251275,
     "end_time": "2024-05-01T20:25:06.265978",
     "exception": false,
     "start_time": "2024-05-01T20:25:01.014703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a7d59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:25:16.748564Z",
     "iopub.status.busy": "2024-05-01T20:25:16.748150Z",
     "iopub.status.idle": "2024-05-01T20:25:23.274973Z",
     "shell.execute_reply": "2024-05-01T20:25:23.273781Z"
    },
    "papermill": {
     "duration": 11.839884,
     "end_time": "2024-05-01T20:25:23.277646",
     "exception": false,
     "start_time": "2024-05-01T20:25:11.437762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "tst['binds'] = 0\n",
    "tst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\n",
    "tst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\n",
    "tst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\n",
    "tst[['id', 'binds']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4914065,
     "sourceId": 8275617,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30514,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5946.405592,
   "end_time": "2024-05-01T20:25:35.242260",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-01T18:46:28.836668",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
