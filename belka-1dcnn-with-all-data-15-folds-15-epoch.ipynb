{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"},{"sourceId":8275617,"sourceType":"datasetVersion","datasetId":4914065},{"sourceId":8785877,"sourceType":"datasetVersion","datasetId":5214038}],"dockerImageVersionId":30514,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialization\n\nThis notebook is forked and inspired from the [BELKA 1DCNN Starter](https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data/notebook).\n\nThis original notebook attempted to encoded the smiles of all the train & test set and saved it locally, this may take up to 1 hour on TPU for each fold. While the original notebook only utilize one fold, there are only 1 fold training, due to the limit of computational power. Therefore, I pre-tained one model for each fold and store the model weights locally so that the prediction results could be combined to make better LB score. The models are stored [here](https://www.kaggle.com/datasets/hugowjd/1dcnn-models-for-belka-competition).\n\nThe encoded data is stored [here](https://www.kaggle.com/datasets/ahmedelfazouan/belka-enc-dataset) , \n\nHow to improve :\n* Change the fold size (better machine may deal with smaller fold number)\n* Try another model like Transformer, or LSTM.\n* Train for more epochs for each folds.\n* Add more features like a one hot encoding of bb2 or bb3.\n* And of ensembling with other models.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/1dcnn-models-for-belka-competition'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:41:11.377603Z","iopub.execute_input":"2024-06-27T14:41:11.377976Z","iopub.status.idle":"2024-06-27T14:41:11.412758Z","shell.execute_reply.started":"2024-06-27T14:41:11.377945Z","shell.execute_reply":"2024-06-27T14:41:11.411856Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/1dcnn-models-for-belka-competition/model-21.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-19.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-1.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-24.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-12.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-9.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-2.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-13.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-4.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-22.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-15.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-7.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-0.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-14.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-11.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-8.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-10.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-20.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-18.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-3.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-5.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-16.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-6.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-17.h5\n/kaggle/input/1dcnn-models-for-belka-competition/model-23.h5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install fastparquet -q","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-27T14:41:15.990022Z","iopub.execute_input":"2024-06-27T14:41:15.990680Z","iopub.status.idle":"2024-06-27T14:41:28.615968Z","shell.execute_reply.started":"2024-06-27T14:41:15.990630Z","shell.execute_reply":"2024-06-27T14:41:28.614788Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import gc\nimport os\nimport pickle\nimport random\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import average_precision_score as APS","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T14:41:28.618366Z","iopub.execute_input":"2024-06-27T14:41:28.618805Z","iopub.status.idle":"2024-06-27T14:41:29.258247Z","shell.execute_reply.started":"2024-06-27T14:41:28.618763Z","shell.execute_reply":"2024-06-27T14:41:29.257422Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class CFG:\n\n    PREPROCESS = False\n    PRETRAINED = True\n    EPOCHS = 20\n    BATCH_SIZE = 4096\n    LR = 1e-3\n    WD = 0.05\n    # Number of folds\n    NBR_FOLDS = 15\n\n    # Only the first fold selected\n    SELECTED_FOLDS = [0,1,2,3,4]\n    EXIST_MODELS = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n\n    SEED = 2222","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:41:29.259291Z","iopub.execute_input":"2024-06-27T14:41:29.259571Z","iopub.status.idle":"2024-06-27T14:41:29.266028Z","shell.execute_reply.started":"2024-06-27T14:41:29.259547Z","shell.execute_reply":"2024-06-27T14:41:29.265139Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import tensorflow as tf\ndef set_seeds(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n\nset_seeds(seed=CFG.SEED)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-27T14:41:29.268092Z","iopub.execute_input":"2024-06-27T14:41:29.268419Z","iopub.status.idle":"2024-06-27T14:41:37.256510Z","shell.execute_reply.started":"2024-06-27T14:41:29.268389Z","shell.execute_reply":"2024-06-27T14:41:37.255538Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def get_strategy():\n    try:\n        # Attempt to use TPU\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # This helps connect to the TPU on environments like Kaggle or Google Colab\n        print(\"Running on TPU:\", tpu.master())\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.TPUStrategy(tpu)\n    except ValueError:\n        # No TPU found, try GPU\n        print(\"TPU not found. Looking for GPU.\")\n        if tf.config.list_physical_devices(\"GPU\"):\n            strategy = tf.distribute.MirroredStrategy()\n            print(\"Running on GPU\")\n        else:\n            # No GPU found, default to CPU\n            print(\"Not on TPU or GPU. Defaulting to CPU.\")\n            strategy = tf.distribute.get_strategy()\n\n    print(\"REPLICAS:\", strategy.num_replicas_in_sync)\n    return strategy\n\n# Usage\nstrategy = get_strategy()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-06-27T14:41:37.257734Z","iopub.execute_input":"2024-06-27T14:41:37.258327Z","iopub.status.idle":"2024-06-27T14:41:39.715393Z","shell.execute_reply.started":"2024-06-27T14:41:37.258299Z","shell.execute_reply":"2024-06-27T14:41:39.714508Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TPU not found. Looking for GPU.\nRunning on GPU\nREPLICAS: 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"if CFG.PREPROCESS:\n    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36}\n    train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n    smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n    assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n    assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n    def encode_smile(smile):\n        tmp = [enc[i] for i in smile]\n        tmp = tmp + [0]*(142-len(tmp))\n        return np.array(tmp).astype(np.uint8)\n\n    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n    smiles_enc = np.stack(smiles_enc)\n    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n    train.to_parquet('train_enc.parquet')\n\n    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n    smiles = test_raw['molecule_smiles'].values\n\n    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n    smiles_enc = np.stack(smiles_enc)\n    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n    test.to_parquet('test_enc.parquet')\n\nelse:\n    train = pd.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet',engine='fastparquet')\n    test = pd.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet',engine='fastparquet')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:41:50.233557Z","iopub.execute_input":"2024-06-27T14:41:50.234342Z","iopub.status.idle":"2024-06-27T14:44:14.322318Z","shell.execute_reply.started":"2024-06-27T14:41:50.234309Z","shell.execute_reply":"2024-06-27T14:44:14.321365Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"Shape of Train set:\", train.shape)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:48:28.853189Z","iopub.execute_input":"2024-06-27T14:48:28.853586Z","iopub.status.idle":"2024-06-27T14:48:28.879017Z","shell.execute_reply.started":"2024-06-27T14:48:28.853556Z","shell.execute_reply":"2024-06-27T14:48:28.877863Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Shape of Train set: (98415610, 145)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   enc0  enc1  enc2  enc3  enc4  enc5  enc6  enc7  enc8  enc9  ...  enc135  \\\n0     8    22     8     8    28    12    27    12    12    12  ...       0   \n1     8    22     8     8    28    12    27    12    12    12  ...       0   \n2     8    22     8     8    28    12    27    12    12    12  ...       0   \n\n   enc136  enc137  enc138  enc139  enc140  enc141  bind1  bind2  bind3  \n0       0       0       0       0       0       0      0      0      0  \n1       0       0       0       0       0       0      0      0      0  \n2       0       0       0       0       0       0      0      0      0  \n\n[3 rows x 145 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enc0</th>\n      <th>enc1</th>\n      <th>enc2</th>\n      <th>enc3</th>\n      <th>enc4</th>\n      <th>enc5</th>\n      <th>enc6</th>\n      <th>enc7</th>\n      <th>enc8</th>\n      <th>enc9</th>\n      <th>...</th>\n      <th>enc135</th>\n      <th>enc136</th>\n      <th>enc137</th>\n      <th>enc138</th>\n      <th>enc139</th>\n      <th>enc140</th>\n      <th>enc141</th>\n      <th>bind1</th>\n      <th>bind2</th>\n      <th>bind3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>28</td>\n      <td>12</td>\n      <td>27</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>28</td>\n      <td>12</td>\n      <td>27</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>28</td>\n      <td>12</td>\n      <td>27</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 145 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"print(\"Shape of Test set:\", test.shape)\ntest.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:48:22.341406Z","iopub.execute_input":"2024-06-27T14:48:22.341798Z","iopub.status.idle":"2024-06-27T14:48:22.361705Z","shell.execute_reply.started":"2024-06-27T14:48:22.341766Z","shell.execute_reply":"2024-06-27T14:48:22.360713Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Shape of Test set: (1674896, 142)\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   enc0  enc1  enc2  enc3  enc4  enc5  enc6  enc7  enc8  enc9  ...  enc132  \\\n0     8    22     8     8     8     8    29     8     3     5  ...       0   \n1     8    22     8     8     8     8    29     8     3     5  ...       0   \n2     8    22     8     8     8     8    29     8     3     5  ...       0   \n\n   enc133  enc134  enc135  enc136  enc137  enc138  enc139  enc140  enc141  \n0       0       0       0       0       0       0       0       0       0  \n1       0       0       0       0       0       0       0       0       0  \n2       0       0       0       0       0       0       0       0       0  \n\n[3 rows x 142 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enc0</th>\n      <th>enc1</th>\n      <th>enc2</th>\n      <th>enc3</th>\n      <th>enc4</th>\n      <th>enc5</th>\n      <th>enc6</th>\n      <th>enc7</th>\n      <th>enc8</th>\n      <th>enc9</th>\n      <th>...</th>\n      <th>enc132</th>\n      <th>enc133</th>\n      <th>enc134</th>\n      <th>enc135</th>\n      <th>enc136</th>\n      <th>enc137</th>\n      <th>enc138</th>\n      <th>enc139</th>\n      <th>enc140</th>\n      <th>enc141</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>29</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>29</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>22</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>29</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 142 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"# 1D-CNN model\ndef OneDCNN_model():\n    with strategy.scope():\n        INP_LEN = 142\n        NUM_FILTERS = 32\n        hidden_dim = 128\n\n        inputs = tf.keras.layers.Input(shape=(INP_LEN,), dtype='int32')\n        x = tf.keras.layers.Embedding(input_dim=36, output_dim=hidden_dim, input_length=INP_LEN, mask_zero = True)(inputs)\n        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*2, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*3, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n        x = tf.keras.layers.GlobalMaxPooling1D()(x)\n\n        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.1)(x)\n        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.1)(x)\n        x = tf.keras.layers.Dense(512, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.1)(x)\n\n        outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n\n        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n        optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n        loss = 'binary_crossentropy'\n        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n        model.compile(\n        loss=loss,\n        optimizer=optimizer,\n        weighted_metrics=weighted_metrics,\n        )\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:44:28.122382Z","iopub.execute_input":"2024-06-27T14:44:28.123099Z","iopub.status.idle":"2024-06-27T14:44:28.134740Z","shell.execute_reply.started":"2024-06-27T14:44:28.123069Z","shell.execute_reply":"2024-06-27T14:44:28.133730Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"%time\nFEATURES = [f'enc{i}' for i in range(142)] # The first 142 encoded columns as features\nTARGETS = ['bind1', 'bind2', 'bind3'] # Three types of binds as targets\n# 15 fold -> only train 1/15 of the entire dataset\n# If we got better machine, we may change NBR_FOLDS smaller\nskf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42) \n                                                                                    \nif CFG.PRETRAINED:\n    print(\"Model Pretrained. Skip Training process.\")\nelse:\n    for fold,(train_idx, valid_idx) in enumerate(skf.split(train, train[TARGETS].sum(1))):\n        if fold in CFG.SELECTED_FOLDS:\n            print(f\"Working on fold {fold}\")\n            X_train = train.loc[train_idx, FEATURES]\n            y_train = train.loc[train_idx, TARGETS]\n            X_val = train.loc[valid_idx, FEATURES]\n            y_val = train.loc[valid_idx, TARGETS]\n\n            es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\n            checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"model-{fold}.h5\",\n                                                                save_best_only=True, save_weights_only=True,\n                                                            mode='min')\n            reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\n            model = OneDCNN_model()\n            history = model.fit(\n                X_train, y_train,\n                validation_data=(X_val, y_val),\n                epochs=CFG.EPOCHS,\n                callbacks=[checkpoint, reduce_lr_loss, es],\n                batch_size=CFG.BATCH_SIZE,\n                verbose=1,\n            )\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:44:34.961729Z","iopub.execute_input":"2024-06-27T14:44:34.962600Z","iopub.status.idle":"2024-06-27T14:44:34.976632Z","shell.execute_reply.started":"2024-06-27T14:44:34.962567Z","shell.execute_reply":"2024-06-27T14:44:34.975706Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 4 µs, sys: 0 ns, total: 4 µs\nWall time: 6.91 µs\nModel Pretrained. Skip Training process.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"all_preds = []\nfor fold in CFG.EXIST_MODELS:\n    model = OneDCNN_model()\n    print(f\"loading weight model-{fold}.h5\")\n    model.load_weights(f\"/kaggle/input/1dcnn-models-for-belka-competition/model-{fold}.h5\")\n    preds = model.predict(test, batch_size = 2*CFG.BATCH_SIZE)\n    all_preds.append(preds)\npreds = np.mean(all_preds, 0)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:44:39.097411Z","iopub.execute_input":"2024-06-27T14:44:39.098045Z","iopub.status.idle":"2024-06-27T14:47:37.633716Z","shell.execute_reply.started":"2024-06-27T14:44:39.098011Z","shell.execute_reply":"2024-06-27T14:47:37.632813Z"},"trusted":true},"outputs":[{"name":"stdout","text":"loading weight model-0.h5\n205/205 [==============================] - 11s 36ms/step\nloading weight model-1.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-2.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-3.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-4.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-5.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-6.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-7.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-8.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-9.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-10.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-11.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-12.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-13.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-14.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-15.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-16.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-17.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-18.h5\n205/205 [==============================] - 7s 35ms/step\nloading weight model-19.h5\n205/205 [==============================] - 7s 35ms/step\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(f\"Shape of Predictions: {len(preds)} * {len(preds[0])}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:47:58.249523Z","iopub.execute_input":"2024-06-27T14:47:58.249894Z","iopub.status.idle":"2024-06-27T14:47:58.254989Z","shell.execute_reply.started":"2024-06-27T14:47:58.249864Z","shell.execute_reply":"2024-06-27T14:47:58.253972Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Shape of Predictions: 1674896 * 3\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Plot","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Assuming 'history' is the object returned from model.fit()\nif CFG.PRETRAINED:\n    print(\"Pretrained -> no plot\")\nelse:\n    train_loss = history.history['loss']\n    val_loss = history.history.get('val_loss', [])  # Use get to avoid errors if validation loss is not available\n\n    train_prec = history.history['avg_precision']\n    val_prec = history.history.get('val_avg_precision', [])  # Similarly for validation accuracy\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(train_loss, label='Train')\n    if val_loss:\n        plt.plot(val_loss, label='Validation')\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(loc='upper right')\n\n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 2)\n    plt.plot(train_prec, label='Train')\n    if val_prec:\n        plt.plot(val_prec, label='Validation')\n    plt.title('Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(loc='lower right')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:48:40.438471Z","iopub.execute_input":"2024-06-27T14:48:40.439280Z","iopub.status.idle":"2024-06-27T14:48:40.448155Z","shell.execute_reply.started":"2024-06-27T14:48:40.439245Z","shell.execute_reply":"2024-06-27T14:48:40.447304Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Pretrained -> no plot\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\ntst['binds'] = 0\ntst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\ntst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\ntst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\ntst[['id', 'binds']].to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T14:49:05.298052Z","iopub.execute_input":"2024-06-27T14:49:05.298828Z","iopub.status.idle":"2024-06-27T14:49:14.785510Z","shell.execute_reply.started":"2024-06-27T14:49:05.298789Z","shell.execute_reply":"2024-06-27T14:49:14.784713Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}